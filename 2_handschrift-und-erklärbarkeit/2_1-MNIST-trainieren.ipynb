{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d59337-2725-4361-932a-d95b4be18f4c",
   "metadata": {},
   "source": [
    "# Handschrifterkennung mit MNIST\n",
    "\n",
    "Im letzten Notebook habt ihr euch mit einfachen Datensätze im zweidimensionalen Raum beschäftigt. Die Auswertung der Modelle war schnell und einfach, die Trainigszeiten kurz. Die Verteilung der Daten in ihrem respektiven Datenraum konnten bequem visualisiert und abgeschätzt werden.\n",
    "\n",
    "In dieser Session werdet ihr das [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) kennen lernen, eine Sammlung handgeschriebener Ziffern von 0 bis 9, mit insgesamt um die 60.000 Datenpunkten. Jedes dieser Bilder wird als 768-dimensionaler Vektor bereitgestellt, welcher ein 28 x 28 - pixel großes Bild darstellen soll.\n",
    "\n",
    "Ladet zunächst den MNIST-Datensatz herunter. Die Daten befinden sich gepackt hinter [diesem link](https://github.com/sebastian-lapuschkin-sideprojects/schuelerpraktikum-2022/blob/master/2_handschrift-und-erkl%C3%A4rbarkeit/2_resources/MNIST.zip). Ladet die Daten herunter, und entpackt den Inhalt im ordner [2_resources](2_resources).\n",
    "\n",
    "\n",
    "Ihr erhaltet nun vier Dateien:\n",
    "\n",
    "`train_images.npy` : Bildbeispiele der Trainingsdaten\n",
    "`train_labels.npy` : Labels der Trainingsdaten\n",
    "\n",
    "`test_images.npy` : Bildbeispiele der Testdaten\n",
    "`test_labels.npy` : Labels der Testdaten\n",
    "\n",
    "Ladet nun all diese Daten mittels der im modul `data_io.py` bereitgestellten Funktionen. Dh. Importiert `data_io` (und ggf weitere module, die ihr bereits kennt und benötigt), ladet alle Daten- und Labelsätze, und legt diese in Variablen ab.\n",
    "\n",
    "Wieviele Test- und Trainingsdaten stehen zur Verfügung? Wie sind die Labels kodiert? Welche Form haben die geladenen Arrays? Macht euch auf dieser fundamentalen Ebene mit den Daten vertraut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d99cc4-0f0c-4c67-a8ca-f189f912d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Modulimporte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b081ae-67e6-44f9-abf3-149ad68ca07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Daten lesen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f309f83-4046-407f-8ef6-3d21d7a26976",
   "metadata": {},
   "source": [
    "Die Date sind as 784-dimensionale Vektoren in den Zeile der Arrays / Matritzen abgelegt. Die Funktionen `plt.scatter`, `plt.plot` (aus dem als `plt` importierten Modul `matplotlib.pyplot` aus dem letzten Tutorial sind für euch daher leider wenig nützlich zur visualisierung. Benutzt die funktionen `np.reshape` (aus dem als `np` importierten Modul `numpy`), um aus einigen Beispielen, bzw den hochdimensionalen Vektoren welche diese repräsentieren, 28 x 28 - dimensionale / pixel große Arrays zu formen.\n",
    "\n",
    "Visualisiert diese Datenpunkte mittels `plt.imshow` und schreibt das Label der Zahl an die Grafik, und nutzt die colormap `binary`. Evtl werdet ihr noch Nutzen für die Funktion `np.transpose` haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e454fd98-5618-452a-80df-45fb3564603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO einzelne Datenpunkte visualisieren\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dbf3c2-062c-411c-9f53-3be5d193e99b",
   "metadata": {},
   "source": [
    "Da nicht einfach alle Daten zeitgleich in einem zweidimensionalen visualisierbar sind wollen wir nun ein \"Embedding\" (also eine \"Einbettung\") verwenden, um die Verteilung der Daten approximiert darzustellen. Macht euch die mit `sklearn.manifold.TSNE` (modulimport nicht vergessen!) zur Verfügung gestellte Implementierung zu nutze, [TSNE](https://www.cs.toronto.edu/~hinton/absps/tsne.pdf)-methode um die Verteilung Hochdimensionalen Zahlen approximiert im $\\mathbb{R}^2$ zu berechnen.\n",
    "\n",
    "Aus einem N x 784 - dimensionalen Array solltet ihr über TSNE ein N x 2 - dimensionales Array erhalten. Die Laufzeit von TSNE hängt von der Komplexität der Daten, als auch der Datenanzahl ab. Das Verfahren arbeitet iterativ und versucht die Punkte ihrer paarweisen ähnlichkeit entsprechend in einen üblicherweise (wie spezifiziert) niedriger-dimensionalen Raum einzubetten. Versucht es daher zunächst ggf erst mit den Testdaten. Ihr könnt TSNE über die signatur so konfigurieren, dass alle verfügbaren Prozessoren genutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da148c72-d0d5-4447-b5de-35115b4ac0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Embedding für einen oder beide der Datensätze berechnen ...,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d57bb9dd-8af2-4470-9e2e-355d986ac8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO und mit plt.scatter visualisieren. Färbt die Punkte mittels der verfügbaren Labels ein. Nutzt eine geeignete Color Map, zb tab10, passend zu den 10 Klassenlabels des MNIST datensatzes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9efba70-8d62-4fff-92b9-464ec8b0d9d2",
   "metadata": {},
   "source": [
    "Diskutiert nun die Daten, und deren Verteilung bevor es weiter zum Training geht. Was erkennt ihr?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33a36a-e4be-4ff1-a4fe-8f3b67172d82",
   "metadata": {},
   "source": [
    "## Trainieren auf MNIST\n",
    "\n",
    "Trainiert nun ein einfaches Multi-Layer-Perceptron (MLP) auf den Daten.\n",
    "Baut jedoch ein Netzwerk `nn` auf, ähnlich wie im Fall der 2D-Daten. Das MLP wird die Daten in Vektorformat erwarten, also NICHT umgeformt zu 28 x 28 pixel großen bilder. Später werden wir ein kleines Convolutional Neural Network nutzen, welches die Daten in Bildform erwartet. Der Trainingsloop ist mit `nn.train()` vorgegeben.\n",
    "\n",
    "Folgende Schritte sind durchzuführen:\n",
    "1) Verschiebt den Wertebereich der Daten von der range [0 255] auf [-1 1]. Teilt dazu zuerst die Matrix durch 127.5, und zieht dann 1 von der Matrix ab. Die Funktionen `np.min` und `np.max` können euch beim Verifizieren der Wertebereiche vor und nach der Transformation helfen.\n",
    "2) Konvertiert die Labels von den gegebenen numerischen klassenlabels zu indikatorvektoren. zb sollte ein Label `[3]` zu `[0,0,0,1,0,0,0,0,0,0]`  umgewandelt werden. Beachtet auch hier das 0-basierte indexing. Wir führen diesen Schritt durch, um einen 10-dimensionalen Indikatorvektor als Label für das 10-Klassen NN zu erhalten.\n",
    "3) Kostruiert als Neuronales Netz `nn` ein `modules.Sequential`-Objekt mit folgenden Schichtmodulen aus den Klassen in `modules`: [1] `Flatten` (sorgt dafür, dass jeder input egal welcher `shape` in einen einachsigen Vektor ausgerollt wird.), [2] ein `Linear` welches den 784-dimensinalen Input mit 960 versteckten dimensinonen verbindet. [3] eine `Rect`-Nichtlinearität, [4] ein weiteres `Linear` welches die vorherigen Features entgegennimmt und wiederrum 960 dimensionen ausgibt, [5] ein weiteres `Rect` und ein abschließendes `Linear` layer welches auf die 10 möglichen Klassen abbildet, sowie ein `SoftMax`, welches die finalen Vorhersagen in Wahrscheinlichkeitswerte zwischen 0 und 1 umwandelt. Dies erleichtert in der Regel bei binär kodierten Labels das Training. \n",
    "\n",
    "Messt abschließend die Performance auf eurem frischen und jetzt noch zufälligen `nn` (ggf sind mehrere Wiederholungen des Experiments nötig). Was beobachtet ihr bei der Performance? Lässt sich ein Bezug zum Datensatz herstellen? (Achtet darauf, die Daten nicht erneut zu prozessieren und zu überschreiben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b1b11e-c951-454c-821f-3b1cb70337ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO transfer pixel values from [0 255] to [-1 1] to satisfy the expected input / training paradigm of the model\n",
    "\n",
    "\n",
    "# TODO transform numeric class labels to vector indicator for uniformity. assume presence of all classes within the label set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d452df1-b3d6-4a55-8694-112c3f9b5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO build model\n",
    "\n",
    "# TODO test initial performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee76eab-516e-456a-a7b8-c54ae4cc5a70",
   "metadata": {},
   "source": [
    "Lasst nun das Training über `nn.train` mehrere Epochen (dh. Wiederholungen des Datensatzes) durchlaufen, beobachtet die Performance auf Trainings- und Testdaten. Welchen Bezug könnt ihr zwischen Modellgröße (Anzahl Schichten, anzahl Dimensionen/Neuronen in diesen Schichten) herstellen? Benutzt und importiert ggf. das modul `time` um die Laufzeiten zu messen.\n",
    "\n",
    "Probiert mehrere Netzarchitekturen durch, und speichert diese mittels der Funktionen in `model_io`. Nutzt ihr `model_io.write(fmt='txt')`, so könnt ihr das Modell mit seiner Architektur und den gelernten Parametern im Menschenlesbaren Textformat ausgeben. Werft einen Blick in die erstellten Dateien.\n",
    "\n",
    "Ihr könntet (und solltet auch, für das folgende und finale Notebook) das je aktuelle Netzwerk am Ende eines Trainingslaufs/zyklus entsprechend numeriert bennannt speichern, damit wir diese Modelle später laden und ihre Entscheidungsstrategien erklären und visualisieren können. Kürzere, bzw sehr kurze Epochen wären hier von Vorteil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825989f8-313a-4c71-bf26-0c85f5c71771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create a for-loop which repeatedly calls a neural network training function, evaluates the current performance, and saves the model after each loop execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fca79-1947-451c-af5e-d168f4a7fb72",
   "metadata": {},
   "source": [
    "After model training has finished, re-use your previously computed TSNE-embedded data as correspondants for the `X_train` or `X_test` (depending on your TSNE input of choice), plot them, but this time instead of using the true labels, predict the labels instead with `nn.forward`, to colorize the dots. You can also plot two figures after one another, one with the predicted labels, one with the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753e1634-067e-409c-b62d-8bc60563660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO plot predicted labels on TSNE-embeddings. If you are fancy, you can do this plot after each training epoch to see class memberships in the model's predictions change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9967aee-9371-46bd-aa88-3d2d3913fcb7",
   "metadata": {},
   "source": [
    "# Entscheidungen auf Zahlen Erklären\n",
    "\n",
    "Anders als im Fall des 2D-Datenraums des ersten Notebooks ist es im aktuellen 784-dimensionalen Datenraum nicht ohne weiteres möglich, eine Entscheidungslinie zu visualisieren, um das Vorhersageverhalten eines Neuronalen Netzes zu verstehen. Wir können uns daher gewisser Techniken der Erklärbaren KI (Explainable AI; XAI) bedienen,um diese Interpretationslücke weitestgehend zu schließen. \n",
    "\n",
    "In diesem Notebook wollen wir daher [LRP](https://dx.doi.org/10.14279/depositonce-7942) verwenden, um heatmaps zu berechnen welche uns zeigen, welche Merkmale (also Pixelregionen) unser trainiertes Modell verwendet um eine Zahl zu interpretieren und zu verstehen.\n",
    "\n",
    "## Code Lesen, Verstehen, und Adaptieren \n",
    "Eure Aufgabe ist es nun, das Beispielscript [lrp_demo.py](https://github.com/sebastian-lapuschkin/lrp_toolbox/blob/master/python/lrp_demo.py) der [LRP Toolbox](https://github.com/sebastian-lapuschkin/lrp_toolbox) zu lesen, und versuchen zu verstehen. Das Skript, als auch die python-implementierung der LRP-Toolbox verwenden exakt die gleichen Neural Network module, wie sie bei euch im ordner [modules](./modules) zu finden sind, mit identischer Funktionalität, welche auch LRP selbst umfasst.\n",
    "\n",
    "Extrahiert zunächst die wesentlichen Bausteine aus [lrp_demo.py](https://github.com/sebastian-lapuschkin/lrp_toolbox/blob/master/python/lrp_demo.py) um einen einzelen Datenpunkt eurer Wahl von dem von euch trainierten NN vorhersagen und über LRP erklären zu lassen. Visualisiert diese Erklärung. Alle dafür notwendigen Codebausteine stehen euch bereits zur Verfügung. Viele Sequenzen im verlinkten Beispielskript werden euch bekannt vorkommen.\n",
    "\n",
    "Sollten eure eigenen Modelle \"nichts taugen\", das Training sollte fehlgeschlagen sein, oder ihr wollt einfach vergleiche ziehen können, stehen euch hinter [diesem link](https://github.com/sebastian-lapuschkin-sideprojects/schuelerpraktikum-2022/raw/a123e6a4518021fb0f7c3b9069588cd49da75025/2_handschrift-und-erkl%C3%A4rbarkeit/2_resources/MNIST_MODELS.zip) einige gut performende Modelle zur Verfügung, die ihr über die Funktionen in `model_io` laden könnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e43adf-245b-4561-afa5-25751c7916e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO predict and visualize individual MNIST digit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf76c0c-ea64-4400-888c-0a093f927678",
   "metadata": {},
   "source": [
    "## Bonusaufgabe\n",
    "Bettet nun die notwendigen Komponenten zur Visualisierung von NN-Entscheidungen in den MNIST-Trainings-Loop ein. Wählt euch initial eine (oder mehrere) Zahlen, auf denen ihr das Verhalten eures NNs während des Trainings beobachten wollt, und lasst euch nach jeder Epoche für diese Zahl eine neue Heatmap berechnen und visualisieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b10ce1-a8b2-454f-8a1b-70468cf58205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
